{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmw5vr-MY6i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgQ1HziQY_Xd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a2c94ebc-34b4-4169-b014-3d502dd45d19"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-09 18:44:13--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 74.125.23.128, 74.125.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-08-09 18:44:13 (96.4 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cxZWGcNf50-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove stop words\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9AwmW5gZBWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bcf82c5f-8bde-4b0e-c911-5557ef8b882b"
      },
      "source": [
        "# reading the JSON\n",
        "\n",
        "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
        "  datastore = json.load(f)\n",
        "\n",
        "plain_sentences = []\n",
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "for item in datastore:\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  sentence = item['headline'].lower()\n",
        "  plain_sentences.append(sentence)\n",
        "  for word in stopwords:\n",
        "    token = \" \" + word + \" \"\n",
        "    sentence = sentence.replace(token, \" \")\n",
        "  sentences.append(sentence)\n",
        "\n",
        "print(len(labels))\n",
        "print(len(sentences))\n",
        "print(sentences[1])\n",
        "print(plain_sentences[1])\n",
        "print(labels[1])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26709\n",
            "26709\n",
            "the 'roseanne' revival catches thorny political mood, better worse\n",
            "the 'roseanne' revival catches up to our thorny political mood, for better and worse\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGpZr0ZeZHFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_size = 20000\n",
        "\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBUjh5n6ZMTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#params \n",
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuwN5KXbZP_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLCgP8ZbZTs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ca20815-0a5c-40b2-f44b-d3169c336132"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpwpeCpdZZFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHsNkjpZf-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to convert them to np array\n",
        "\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtSIp2x9ZpMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "dbf5688e-ba97-459a-d4ea-ffd647aaaf76"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 120, 16)           16000     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 120, 128)          41472     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                1560      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 100,273\n",
            "Trainable params: 100,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fryfKQgOisix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint \n",
        "\n",
        "filepath = \"sarcasm-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto') "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoQUnkgxZ4LX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a11f1e28-92d3-4514-876b-0842ef29be41"
      },
      "source": [
        "num_epochs = 15\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=1, callbacks=[checkpoint])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.7802\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76792, saving model to sarcasm-model-01-0.77.hdf5\n",
            "625/625 [==============================] - 103s 165ms/step - loss: 0.4377 - accuracy: 0.7802 - val_loss: 0.4495 - val_accuracy: 0.7679\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.7958\n",
            "Epoch 00002: val_accuracy improved from 0.76792 to 0.77925, saving model to sarcasm-model-02-0.78.hdf5\n",
            "625/625 [==============================] - 104s 167ms/step - loss: 0.4047 - accuracy: 0.7958 - val_loss: 0.4400 - val_accuracy: 0.7793\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.8047\n",
            "Epoch 00003: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 104s 167ms/step - loss: 0.3919 - accuracy: 0.8047 - val_loss: 0.4380 - val_accuracy: 0.7730\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8156\n",
            "Epoch 00004: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 105s 167ms/step - loss: 0.3732 - accuracy: 0.8156 - val_loss: 0.4466 - val_accuracy: 0.7751\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.8188\n",
            "Epoch 00005: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 104s 166ms/step - loss: 0.3632 - accuracy: 0.8188 - val_loss: 0.4439 - val_accuracy: 0.7779\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.8256\n",
            "Epoch 00006: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 104s 166ms/step - loss: 0.3559 - accuracy: 0.8256 - val_loss: 0.4654 - val_accuracy: 0.7711\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.8307\n",
            "Epoch 00007: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 104s 166ms/step - loss: 0.3469 - accuracy: 0.8307 - val_loss: 0.4524 - val_accuracy: 0.7736\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.8335\n",
            "Epoch 00008: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 103s 165ms/step - loss: 0.3391 - accuracy: 0.8335 - val_loss: 0.4716 - val_accuracy: 0.7718\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.8406\n",
            "Epoch 00009: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 102s 164ms/step - loss: 0.3321 - accuracy: 0.8406 - val_loss: 0.4769 - val_accuracy: 0.7721\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.8427\n",
            "Epoch 00010: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 102s 164ms/step - loss: 0.3266 - accuracy: 0.8427 - val_loss: 0.4834 - val_accuracy: 0.7709\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.8479\n",
            "Epoch 00011: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 102s 163ms/step - loss: 0.3176 - accuracy: 0.8479 - val_loss: 0.5122 - val_accuracy: 0.7627\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.8512\n",
            "Epoch 00012: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 107s 172ms/step - loss: 0.3108 - accuracy: 0.8512 - val_loss: 0.4966 - val_accuracy: 0.7691\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.8529\n",
            "Epoch 00013: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 104s 166ms/step - loss: 0.3066 - accuracy: 0.8529 - val_loss: 0.5349 - val_accuracy: 0.7722\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8591\n",
            "Epoch 00014: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 102s 163ms/step - loss: 0.2982 - accuracy: 0.8591 - val_loss: 0.5313 - val_accuracy: 0.7685\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.8599\n",
            "Epoch 00015: val_accuracy did not improve from 0.77925\n",
            "625/625 [==============================] - 102s 163ms/step - loss: 0.2950 - accuracy: 0.8599 - val_loss: 0.5222 - val_accuracy: 0.7673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfGcXEmVrIlr",
        "colab_type": "text"
      },
      "source": [
        "**Model 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udh7_XxaaAPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XFvoRtlrMmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "400a78e4-28ad-447b-9039-322b0070d94c"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 120, 16)           16000     \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 116, 64)           5184      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 29, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 54,273\n",
            "Trainable params: 54,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBcWx47QrPEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint \n",
        "\n",
        "filepath = \"sarcasm-model2-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto') "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA1ZD8-YrSRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3d493ec-361f-4acb-85b5-f9ce00dc0202"
      },
      "source": [
        "num_epochs = 15\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=1, callbacks=[checkpoint])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.5722 - accuracy: 0.6752\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.75242, saving model to sarcasm-model2-01-0.75.hdf5\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.5721 - accuracy: 0.6753 - val_loss: 0.4765 - val_accuracy: 0.7524\n",
            "Epoch 2/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4357 - accuracy: 0.7841\n",
            "Epoch 00002: val_accuracy improved from 0.75242 to 0.76628, saving model to sarcasm-model2-02-0.77.hdf5\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4354 - accuracy: 0.7843 - val_loss: 0.4504 - val_accuracy: 0.7663\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4017 - accuracy: 0.8043\n",
            "Epoch 00003: val_accuracy improved from 0.76628 to 0.77761, saving model to sarcasm-model2-03-0.78.hdf5\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.4017 - accuracy: 0.8043 - val_loss: 0.4543 - val_accuracy: 0.7776\n",
            "Epoch 4/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.3701 - accuracy: 0.8249\n",
            "Epoch 00004: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.3702 - accuracy: 0.8248 - val_loss: 0.4634 - val_accuracy: 0.7746\n",
            "Epoch 5/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.8441\n",
            "Epoch 00005: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.3337 - accuracy: 0.8442 - val_loss: 0.5366 - val_accuracy: 0.7699\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2977 - accuracy: 0.8647\n",
            "Epoch 00006: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.2977 - accuracy: 0.8647 - val_loss: 0.5377 - val_accuracy: 0.7649\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.8821\n",
            "Epoch 00007: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 17s 26ms/step - loss: 0.2585 - accuracy: 0.8821 - val_loss: 0.5399 - val_accuracy: 0.7642\n",
            "Epoch 8/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.2232 - accuracy: 0.9033\n",
            "Epoch 00008: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.2231 - accuracy: 0.9033 - val_loss: 0.6485 - val_accuracy: 0.7624\n",
            "Epoch 9/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2000 - accuracy: 0.9116\n",
            "Epoch 00009: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.2001 - accuracy: 0.9114 - val_loss: 0.6660 - val_accuracy: 0.7514\n",
            "Epoch 10/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9214\n",
            "Epoch 00010: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.1805 - accuracy: 0.9214 - val_loss: 0.7311 - val_accuracy: 0.7585\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1624 - accuracy: 0.9294\n",
            "Epoch 00011: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.1624 - accuracy: 0.9294 - val_loss: 0.7882 - val_accuracy: 0.7541\n",
            "Epoch 12/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9353\n",
            "Epoch 00012: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.1508 - accuracy: 0.9352 - val_loss: 0.7091 - val_accuracy: 0.7529\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9419\n",
            "Epoch 00013: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.1400 - accuracy: 0.9419 - val_loss: 0.9507 - val_accuracy: 0.7563\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9451\n",
            "Epoch 00014: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.1309 - accuracy: 0.9451 - val_loss: 0.8527 - val_accuracy: 0.7551\n",
            "Epoch 15/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.9475\n",
            "Epoch 00015: val_accuracy did not improve from 0.77761\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.1238 - accuracy: 0.9474 - val_loss: 0.8470 - val_accuracy: 0.7505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEHU839QrUqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}