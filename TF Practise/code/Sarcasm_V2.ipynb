{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Category 4  Sarcasm V2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puu8rAtWe9LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1168b59-11d2-421c-a3fe-3bc50d86faf5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3FHUji8fH0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tensorflow==2.0.0\n",
        "# import tensorflow as tf\n",
        "# print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-06-gnHfLU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bdd7e7fa-3e3a-4f3a-9565-6c257b4c2517"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-22 23:25:30--  https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-08-22 23:25:30 (186 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcV3cKc7fcRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove stop words\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik9bEiNJffOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "33749e13-599c-4c14-e91e-0107ff2ed906"
      },
      "source": [
        "\n",
        "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
        "  datastore = json.load(f)\n",
        "\n",
        "plain_sentences = []\n",
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "for item in datastore:\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  sentence = item['headline'].lower()\n",
        "  plain_sentences.append(sentence)\n",
        "  for word in stopwords:\n",
        "    token = \" \" + word + \" \"\n",
        "    sentence = sentence.replace(token, \" \")\n",
        "  sentences.append(sentence)\n",
        "\n",
        "print(len(labels))\n",
        "print(len(sentences))\n",
        "print(sentences[1])\n",
        "print(plain_sentences[1])\n",
        "print(labels[1])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26709\n",
            "26709\n",
            "the 'roseanne' revival catches thorny political mood, better worse\n",
            "the 'roseanne' revival catches up to our thorny political mood, for better and worse\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZL2t8HFfhN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZSoG7jkfj5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmdo5KgufoaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2VjI9_cfsFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4458fac-2b94-4b9e-b877-c629efaf1532"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JADMgAqBftgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4805ffc2-22a9-407c-c17c-3505466db3f3"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNEv0qcwfvDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9IctpQ_fw5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# need to convert them to np array\n",
        "\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R27M2F8OfzUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a8aff883-6047-4572-f4f7-b038094add15"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    # tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    # tf.keras.layers.Dense(24, activation='relu'),\n",
        "    # tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    # # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    # # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    # # tf.keras.layers.Dense(24, activation='relu'),\n",
        "    # # tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 120, 16)           16000     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 64)                12544     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 24)                1560      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 30,129\n",
            "Trainable params: 30,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88XJ3GkFf9Wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "170ab16e-7916-43aa-dafc-519a8258c1a2"
      },
      "source": [
        "num_epochs = 50\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 6709 samples\n",
            "Epoch 1/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.1502 - accuracy: 0.9304 - val_loss: 1.2324 - val_accuracy: 0.7563\n",
            "Epoch 2/50\n",
            "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.1501 - accuracy: 0.9313 - val_loss: 1.3721 - val_accuracy: 0.7554\n",
            "Epoch 3/50\n",
            "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.1430 - accuracy: 0.9329 - val_loss: 1.3881 - val_accuracy: 0.7602\n",
            "Epoch 4/50\n",
            "20000/20000 [==============================] - 43s 2ms/sample - loss: 0.1411 - accuracy: 0.9341 - val_loss: 1.4844 - val_accuracy: 0.7582\n",
            "Epoch 5/50\n",
            "20000/20000 [==============================] - 43s 2ms/sample - loss: 0.1349 - accuracy: 0.9359 - val_loss: 1.5973 - val_accuracy: 0.7566\n",
            "Epoch 6/50\n",
            "20000/20000 [==============================] - 43s 2ms/sample - loss: 0.1302 - accuracy: 0.9381 - val_loss: 1.5785 - val_accuracy: 0.7550\n",
            "Epoch 7/50\n",
            "20000/20000 [==============================] - 43s 2ms/sample - loss: 0.1315 - accuracy: 0.9369 - val_loss: 1.6088 - val_accuracy: 0.7590\n",
            "Epoch 8/50\n",
            "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.1252 - accuracy: 0.9399 - val_loss: 1.7663 - val_accuracy: 0.7564\n",
            "Epoch 9/50\n",
            "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.1247 - accuracy: 0.9401 - val_loss: 1.7484 - val_accuracy: 0.7511\n",
            "Epoch 10/50\n",
            "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.1164 - accuracy: 0.9444 - val_loss: 1.8005 - val_accuracy: 0.7527\n",
            "Epoch 11/50\n",
            "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.1159 - accuracy: 0.9433 - val_loss: 1.8633 - val_accuracy: 0.7556\n",
            "Epoch 12/50\n",
            "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.1118 - accuracy: 0.9452 - val_loss: 2.0002 - val_accuracy: 0.7550\n",
            "Epoch 13/50\n",
            "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.1090 - accuracy: 0.9459 - val_loss: 2.0280 - val_accuracy: 0.7535\n",
            "Epoch 14/50\n",
            "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.1092 - accuracy: 0.9453 - val_loss: 2.0626 - val_accuracy: 0.7563\n",
            "Epoch 15/50\n",
            "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.1076 - accuracy: 0.9479 - val_loss: 2.0140 - val_accuracy: 0.7591\n",
            "Epoch 16/50\n",
            "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.1065 - accuracy: 0.9478 - val_loss: 2.0330 - val_accuracy: 0.7533\n",
            "Epoch 17/50\n",
            "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.1064 - accuracy: 0.9485 - val_loss: 2.0772 - val_accuracy: 0.7559\n",
            "Epoch 18/50\n",
            "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.0974 - accuracy: 0.9510 - val_loss: 2.2159 - val_accuracy: 0.7544\n",
            "Epoch 19/50\n",
            "20000/20000 [==============================] - 45s 2ms/sample - loss: 0.1004 - accuracy: 0.9481 - val_loss: 2.1084 - val_accuracy: 0.7530\n",
            "Epoch 20/50\n",
            "20000/20000 [==============================] - 44s 2ms/sample - loss: 0.0917 - accuracy: 0.9523 - val_loss: 2.2435 - val_accuracy: 0.7526\n",
            "Epoch 21/50\n",
            "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.1056 - accuracy: 0.9488 - val_loss: 2.2755 - val_accuracy: 0.7511\n",
            "Epoch 22/50\n",
            "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.0960 - accuracy: 0.9534 - val_loss: 2.2153 - val_accuracy: 0.7527\n",
            "Epoch 23/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0866 - accuracy: 0.9546 - val_loss: 2.4030 - val_accuracy: 0.7518\n",
            "Epoch 24/50\n",
            "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.0916 - accuracy: 0.9549 - val_loss: 2.3072 - val_accuracy: 0.7514\n",
            "Epoch 25/50\n",
            "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.0878 - accuracy: 0.9556 - val_loss: 2.4050 - val_accuracy: 0.7541\n",
            "Epoch 26/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0894 - accuracy: 0.9554 - val_loss: 2.4531 - val_accuracy: 0.7535\n",
            "Epoch 27/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0817 - accuracy: 0.9576 - val_loss: 2.5374 - val_accuracy: 0.7506\n",
            "Epoch 28/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0890 - accuracy: 0.9553 - val_loss: 2.6192 - val_accuracy: 0.7532\n",
            "Epoch 29/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0836 - accuracy: 0.9561 - val_loss: 2.6108 - val_accuracy: 0.7521\n",
            "Epoch 30/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0782 - accuracy: 0.9600 - val_loss: 2.6297 - val_accuracy: 0.7503\n",
            "Epoch 31/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0755 - accuracy: 0.9606 - val_loss: 2.6596 - val_accuracy: 0.7485\n",
            "Epoch 32/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0839 - accuracy: 0.9585 - val_loss: 2.7103 - val_accuracy: 0.7474\n",
            "Epoch 33/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0824 - accuracy: 0.9578 - val_loss: 2.7128 - val_accuracy: 0.7523\n",
            "Epoch 34/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0755 - accuracy: 0.9614 - val_loss: 2.8730 - val_accuracy: 0.7509\n",
            "Epoch 35/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0800 - accuracy: 0.9590 - val_loss: 2.6820 - val_accuracy: 0.7478\n",
            "Epoch 36/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0775 - accuracy: 0.9592 - val_loss: 2.6934 - val_accuracy: 0.7496\n",
            "Epoch 37/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0759 - accuracy: 0.9617 - val_loss: 2.8884 - val_accuracy: 0.7511\n",
            "Epoch 38/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0736 - accuracy: 0.9610 - val_loss: 2.7597 - val_accuracy: 0.7488\n",
            "Epoch 39/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0667 - accuracy: 0.9650 - val_loss: 2.9191 - val_accuracy: 0.7506\n",
            "Epoch 40/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0728 - accuracy: 0.9614 - val_loss: 2.9471 - val_accuracy: 0.7432\n",
            "Epoch 41/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0792 - accuracy: 0.9604 - val_loss: 2.7645 - val_accuracy: 0.7485\n",
            "Epoch 42/50\n",
            "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.0692 - accuracy: 0.9632 - val_loss: 3.0312 - val_accuracy: 0.7514\n",
            "Epoch 43/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0620 - accuracy: 0.9666 - val_loss: 3.1253 - val_accuracy: 0.7462\n",
            "Epoch 44/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0695 - accuracy: 0.9638 - val_loss: 3.0163 - val_accuracy: 0.7503\n",
            "Epoch 45/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0702 - accuracy: 0.9637 - val_loss: 3.1295 - val_accuracy: 0.7505\n",
            "Epoch 46/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0693 - accuracy: 0.9653 - val_loss: 3.0385 - val_accuracy: 0.7447\n",
            "Epoch 47/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0661 - accuracy: 0.9653 - val_loss: 3.1245 - val_accuracy: 0.7493\n",
            "Epoch 48/50\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 0.0620 - accuracy: 0.9678 - val_loss: 3.1269 - val_accuracy: 0.7506\n",
            "Epoch 49/50\n",
            "20000/20000 [==============================] - 41s 2ms/sample - loss: 0.0649 - accuracy: 0.9669 - val_loss: 3.3030 - val_accuracy: 0.7478\n",
            "Epoch 50/50\n",
            "20000/20000 [==============================] - 42s 2ms/sample - loss: 0.0620 - accuracy: 0.9667 - val_loss: 3.0770 - val_accuracy: 0.7448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhdd1bjOgCJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('1bi_2_updated.h5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv0s0KMFl6uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}